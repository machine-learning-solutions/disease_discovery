{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The project is detecting the existence of hepatitis \n",
    "#Supervised Task \n",
    "#Classification Problem\n",
    "# Data source : https://archive.ics.uci.edu/ml/datasets/hepatitis  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                  0\n",
      "sex                  0\n",
      "steroid              1\n",
      "antivirals           0\n",
      "fatigue              1\n",
      "malaise              1\n",
      "anorexia             1\n",
      "liver_big           10\n",
      "liver_firm          11\n",
      "spleen_palpable    125\n",
      "spiders              5\n",
      "ascites              5\n",
      "varices              5\n",
      "bilirubin            6\n",
      "alk_phosphate       29\n",
      "sgot                 4\n",
      "albumin             16\n",
      "protime             67\n",
      "histology            0\n",
      "class                0\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_151196/129003314.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# 5) Features distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# 6) Features corellation Matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "#Libraries importing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "np.random.seed(10)\n",
    "\n",
    "#Uploading Dataset\n",
    "dataset=pd.read_csv(\"dataset/hepatitis.csv\")\n",
    "dataset.head(20)\n",
    "\n",
    "\n",
    "# A) Data Exploring\n",
    "\n",
    "# 1) Encoding Binary Features\n",
    "dataset[\"sex\"]=dataset[\"sex\"].apply(lambda x: 1 if x==\"male\" else (0 if x==\"female\" else np.nan))\n",
    "dataset[\"steroid\"]=dataset[\"steroid\"].apply(lambda x: 1 if x==True else (0 if x==False else np.nan))\n",
    "dataset[\"antivirals\"]=dataset[\"antivirals\"].apply(lambda x: 1 if x==True else (0 if x==False else np.nan))\n",
    "dataset[\"fatigue\"]=dataset[\"fatigue\"].apply(lambda x: 1 if x==True else (0 if x==False else np.nan))\n",
    "dataset[\"malaise\"]=dataset[\"malaise\"].apply(lambda x: 1 if x==True else (0 if x==False else np.nan))\n",
    "dataset[\"anorexia\"]=dataset[\"anorexia\"].apply(lambda x: 1 if x==True else (0 if x==False else np.nan))\n",
    "dataset[\"liver_big\"]=dataset[\"liver_big\"].apply(lambda x: 1 if x==True else (0 if x==False else np.nan))\n",
    "dataset[\"liver_firm\"]=dataset[\"liver_firm\"].apply(lambda x: 1 if x==True else (0 if x==False else np.nan))\n",
    "dataset[\"spleen_palpable\"]=dataset[\"spleen_palpable\"].apply(lambda x: 1 if x==True else (0 if x==\"B\" else np.nan))\n",
    "dataset[\"spiders\"]=dataset[\"spiders\"].apply(lambda x: 1 if x==True else (0 if x==False else np.nan))\n",
    "dataset[\"ascites\"]=dataset[\"ascites\"].apply(lambda x: 1 if x==True else (0 if x==False else np.nan))\n",
    "dataset[\"varices\"]=dataset[\"varices\"].apply(lambda x: 1 if x==True else (0 if x==False else np.nan))\n",
    "dataset[\"histology\"]=dataset[\"histology\"].apply(lambda x: 1 if x==True else (0 if x==False else np.nan))\n",
    "dataset[\"class\"]=dataset[\"class\"].apply(lambda x: 1 if x==\"live\" else (0 if x==\"die\" else np.nan))\n",
    "\n",
    "# 2) Missing Values discovering \n",
    "count=dataset.isnull().sum()\n",
    "print(count)\n",
    "# 3) Dealing with Missing Values\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp1 = SimpleImputer(strategy=\"mean\") \n",
    "dataset[[\"bilirubin\"]]=imp1.fit_transform(dataset[[\"bilirubin\"]])\n",
    "dataset[[\"alk_phosphate\"]]=imp1.fit_transform(dataset[[\"alk_phosphate\"]])\n",
    "dataset[[\"sgot\"]]=imp1.fit_transform(dataset[[\"sgot\"]])\n",
    "dataset[[\"albumin\"]]=imp1.fit_transform(dataset[[\"albumin\"]])\n",
    "dataset[[\"protime\"]]=imp1.fit_transform(dataset[[\"protime\"]])\n",
    "dataset.head(10)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from numpy import nan\n",
    "imp2 = SimpleImputer(strategy=\"most_frequent\") \n",
    "dataset[[\"steroid\"]]=imp2.fit_transform(dataset[[\"steroid\"]])\n",
    "dataset[[\"antivirals\"]]=imp2.fit_transform(dataset[[\"antivirals\"]])\n",
    "dataset[[\"fatigue\"]]=imp2.fit_transform(dataset[[\"fatigue\"]])\n",
    "dataset[[\"malaise\"]]=imp2.fit_transform(dataset[[\"malaise\"]])\n",
    "dataset[[\"anorexia\"]]=imp2.fit_transform(dataset[[\"anorexia\"]])\n",
    "dataset[[\"liver_big\"]]=imp2.fit_transform(dataset[[\"liver_big\"]])\n",
    "dataset[[\"liver_firm\"]]=imp2.fit_transform(dataset[[\"liver_firm\"]])\n",
    "dataset[[\"spleen_palpable\"]]=imp2.fit_transform(dataset[[\"spleen_palpable\"]])\n",
    "dataset[[\"spiders\"]]=imp2.fit_transform(dataset[[\"spiders\"]])\n",
    "dataset[[\"ascites\"]]=imp2.fit_transform(dataset[[\"ascites\"]])\n",
    "dataset[[\"varices\"]]=imp2.fit_transform(dataset[[\"varices\"]])\n",
    "dataset[[\"histology\"]]=imp2.fit_transform(dataset[[\"histology\"]])\n",
    "dataset.head(10)\n",
    "\n",
    "# 4) Outliers Discovering by descibing\n",
    "dataset.describe()\n",
    "\n",
    "# 5) Features distribution\n",
    "x_train.hist(figsize=(15,15),layout=(3,7),bins=25)\n",
    "\n",
    "# 6) Features corellation Matrix\n",
    "#Libraries importing \n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "#corellation Matrix before dropping\n",
    "plt.figure(figsize=(18,8))\n",
    "corr=dataset.corr()\n",
    "sb.heatmap(corr,annot=True)\n",
    "\n",
    "\n",
    "# 7) Dataset splitting\n",
    "features=dataset.drop([\"class\"],axis=1)\n",
    "target=dataset[\"class\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(features,target,test_size=0.25,stratify=target,random_state=10)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option(\"max_rows\", None)\n",
    "\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of the Model is: 0.9743589743589743\n",
      "The Precision of the Model is: 0.96875\n",
      "The Recall of the Model is: 1.0\n",
      "The F1 Score of the Model is: 0.9841269841269841\n"
     ]
    }
   ],
   "source": [
    "# 3-2)  K-Nearest Neighbors Classifier with PCA\n",
    "\n",
    "#Libraries importing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score,accuracy_score,recall_score,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Dataset splitting\n",
    "features=dataset.drop([\"class\"],axis=1)\n",
    "target=dataset[\"class\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(features,target,test_size=0.25,stratify=target,random_state=1)\n",
    "\n",
    "\n",
    "#Defining in instance for Standerizing\n",
    "std=StandardScaler()\n",
    "\n",
    "#Defining an instance for PCA DR Algorithm\n",
    "pca=PCA(n_components=0.95)\n",
    "\n",
    "#Defining an instance for K-Nearest Neighbor Classifiers\n",
    "knn = KNeighborsClassifier(n_neighbors=4, n_jobs=-1)\n",
    "\n",
    "#Standrizing Process\n",
    "x_train_std=std.fit_transform(x_train)\n",
    "x_test_std=std.transform(x_test)\n",
    "\n",
    "#Applying Feature extraction using PCA\n",
    "features_reduced=pca.fit_transform(x_train_std)\n",
    "x_test=pca.transform(x_test_std)\n",
    "\n",
    "#Creating a Model with train and test\n",
    "model=knn.fit(features_reduced,y_train)\n",
    "y_predict=model.predict(x_test)\n",
    "\n",
    "#Evaluate the model\n",
    "print(\"The Accuracy of the Model is:\",accuracy_score(y_test,y_predict))\n",
    "print(\"The Precision of the Model is:\",precision_score(y_test,y_predict))\n",
    "print(\"The Recall of the Model is:\",recall_score(y_test,y_predict))\n",
    "print(\"The F1 Score of the Model is:\",f1_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accurecy of the Model is: 0.8717948717948718\n",
      "The Precision of the Model is: 0.9333333333333333\n",
      "The Recall of the Model is: 0.9032258064516129\n",
      "The F1 Score of the Model is: 0.9180327868852459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i in n:\\n    for j in le:\\n    \\n        adb=AdaBoostClassifier(n_estimators=i,random_state=50,learning_rate=j)\\n        model= adb.fit(x_train_std,y_train)\\n        y_predict=model.predict(x_test_std)\\n        p=precision_score(y_test,y_predict)\\n        if p>max_p:\\n            max_p=p\\n            k=i\\n            m=j\\nprint(max_p)\\nprint(k)\\nprint(m)\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-1) AdaBoost Classifier\n",
    "\n",
    "#import libraries\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import precision_score,accuracy_score,recall_score,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Dataset splitting\n",
    "features=dataset.drop([\"class\"],axis=1)\n",
    "target=dataset[\"class\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(features,target,test_size=0.25,stratify=target,random_state=10)\n",
    "\n",
    "#identifing the maximum precision\n",
    "max_p=0.93\n",
    "#identifing the range of random state\n",
    "np.random.seed(50)\n",
    "n=np.random.randint(300,600,5)\n",
    "#identifing the range of learning rate\n",
    "le=np.random.random(5)+0.01\n",
    "\n",
    "#Defining an instance for AdaBoost Classifier\n",
    "adb=AdaBoostClassifier(n_estimators=409,random_state=50,learning_rate=0.7818939948397136)\n",
    "\n",
    "#Creating a Model with train and test\n",
    "model= adb.fit(x_train,y_train)\n",
    "y_predict=model.predict(x_test)\n",
    "\n",
    "#Evaluate the model\n",
    "print(\"The Accurecy of the Model is:\",accuracy_score(y_test,y_predict))\n",
    "print(\"The Precision of the Model is:\",precision_score(y_test,y_predict))\n",
    "print(\"The Recall of the Model is:\",recall_score(y_test,y_predict))\n",
    "print(\"The F1 Score of the Model is:\",f1_score(y_test,y_predict))\n",
    "\n",
    "\n",
    "#Tell me what is the feature do i delete to imporove precision\n",
    "from sklearn.feature_selection import RFECV\n",
    "rf=RFECV(estimator=adb,step=1,scoring=\"accuracy\")\n",
    "#fitting and transformation\n",
    "rf.fit(x_train,y_train)\n",
    "rf.transform(x_train)\n",
    "#the result bu nothing changed\n",
    "print(rf.support_)\n",
    "\n",
    "for i in n:\n",
    "    for j in le:\n",
    "    \n",
    "        adb=AdaBoostClassifier(n_estimators=i,random_state=50,learning_rate=j)\n",
    "        model= adb.fit(x_train_std,y_train)\n",
    "        y_predict=model.predict(x_test_std)\n",
    "        p=precision_score(y_test,y_predict)\n",
    "        if p>max_p:\n",
    "            max_p=p\n",
    "            k=i\n",
    "            m=j\n",
    "print(max_p)\n",
    "print(k)\n",
    "print(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of the Model is: 0.8461538461538461\n",
      "The Precision of the Model is: 0.8571428571428571\n",
      "The Recall of the Model is: 0.967741935483871\n",
      "The F1 Score of the Model is: 0.909090909090909\n",
      "[False False False  True False]\n"
     ]
    }
   ],
   "source": [
    "# 4-4) Decision Tree Classifier with KERNAL PCA\n",
    "\n",
    "#Libraries importing\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score,accuracy_score,recall_score,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Dataset splitting\n",
    "features=dataset.drop([\"class\",\"sex\",\"steroid\",\"antivirals\",\"fatigue\",\"malaise\",\"anorexia\",\"liver_big\",\"spleen_palpable\",\"spiders\",\"ascites\",\"alk_phosphate\",\"sgot\",\"protime\",\"histology\"],axis=1)\n",
    "target=dataset[\"class\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(features,target,test_size=0.25,stratify=target,random_state=10)\n",
    "\n",
    "#Defining an instance for KERNAL PCA DR Algorithm\n",
    "kpca = KernelPCA()\n",
    "\n",
    "#Defining an instance for Decision Tree Classifier\n",
    "decisiontree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "#Applying Feature extraction using KERNAL PCA\n",
    "features_reduced=kpca.fit_transform(x_train_std)\n",
    "x_test=kpca.transform(x_test_std)\n",
    "\n",
    "#Creating a Model with train and test\n",
    "model=decisiontree.fit(features_reduced,y_train)\n",
    "y_predict=model.predict(x_test)\n",
    "\n",
    "#Evaluate the model\n",
    "print(\"The Accuracy of the Model is:\",accuracy_score(y_test,y_predict))\n",
    "print(\"The Precision of the Model is:\",precision_score(y_test,y_predict))\n",
    "print(\"The Recall of the Model is:\",recall_score(y_test,y_predict))\n",
    "print(\"The F1 Score of the Model is:\",f1_score(y_test,y_predict))\n",
    "\n",
    "#importing libraries\n",
    "from sklearn.feature_selection import RFECV\n",
    "#identifing an object for REFCV\n",
    "lr=RFECV(estimator=decisiontree,step=1,scoring=\"precision\")\n",
    "#fitting and transformation\n",
    "lr.fit(x_train,y_train)\n",
    "lr.transform(x_train)\n",
    "#the result bu nothing changed\n",
    "print(lr.support_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
